You will find below a list of papers related to static code analysis done by deep learning models (especially LLM). 
You are welcome to contribute.

-----

| Title                                                                                                                                | Org                                              | Thread / Article / Video / Podcasts                                                                                                     | Date    |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------- | ------- |
| [Retrieval meets Long Context Large Language Models](https://arxiv.org/abs/2310.03025)                                               | NVIDIA                                           | [@omarsar0](https://twitter.com/omarsar0/status/1709749178199318545)                                                                    | 10-2023 |
| [CodePlan: Repository-level Coding using LLMs and Planning](https://arxiv.org/abs/2309.12499)                                        | Microsoft Research                               |                                                                                                                                         | 09-2023 |
| [LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models](https://arxiv.org/pdf/2309.12307.pdf)                        | CHUK, MIT                                        |                                                                                                                                         | 09-2023 |
| [XGen-7B Technical Report](https://arxiv.org/pdf/2309.03450.pdf)                                                                     | Salesforce                                       | [Salesforce's blog post](https://blog.salesforceairesearch.com/xgen/)                                                                   | 09-2023 |
| [Code Llama: Open Foundation Models for Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/) | Meta                                             | [Meta's blog post](https://ai.meta.com/blog/code-llama-large-language-model-coding/)                                                    | 08-2023 |
| [Simple synthetic data reduces sycophancy in large language models](https://arxiv.org/abs/2308.03958)                                | DeepMind                                         | [0xtotem](https://twitter.com/0xTotem/status/1691028914892611584)                                                                       | 08-2023 |
| [PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback](https://arxiv.org/abs/2307.14936)                      | Huawei Cloud, Chinese Academy Of Science, Peking |                                                                                                                                         | 07-2023 |
| [Predicting Code Coverage Execution](https://arxiv.org/abs/2307.13383)                                                               | Microsoft                                        |                                                                                                                                         | 07-2023 |
| [PUMA: Secure Inference of LLaMA-7B in Five Minutes](https://arxiv.org/abs/2307.12533)                                               | Ant Group (private, Alibaba)                     | [Feral Machine](https://feralmachine.com/notes-on-on-the-origin-of-llms-an-evolutionary-tree-and-graph-for-15821-large-language-models) | 07-2023 |
| [On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models](https://arxiv.org/abs/2307.09793)           | Canyon Crest Academy, Stanford                   |                                                                                                                                         | 07-2023 |
| [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172)                                        | Stanford, Berkeley                               | [Deep Papers](https://www.deeppapers.dev/2112256/13296608-lost-in-the-middle-how-language-models-use-long-contexts?t=0)                 | 07-2023 |
| [Focused Transformer: Contrastive Training for Context Scaling](https://arxiv.org/abs/2307.03170)                                    | IDEAS NCBR, Deep Mind                            |                                                                                                                                         | 07-2023 |
| [LongNet: Scaling Transformers to 1,000,000,000 Tokens](https://arxiv.org/abs/2307.02486)                                            | Microsoft Research                               |                                                                                                                                         | 07-2023 |
| [Textbooks are all you need](https://arxiv.org/abs/2306.11644)                                                                       | Microsoft Research                               | [0xtotem](https://twitter.com/0xTotem/status/1671508966377943042)                                                                       | 06-2023 |
| [RepoFusion: Training Code Models to Understand Your Repository](https://arxiv.org/abs//2306.10998)                                  | ServiceNow Research                              | [DishaShrivasta9](https://twitter.com/DishaShrivasta9/status/1674859047206416384)                                                       | 06-2023 |
| [Do you still need a manual smart contract audit?](https://arxiv.org/abs/2306.12338)                                                 | Imperial College London                          | [HatforceSec](https://twitter.com/HatforceSec/status/1671758690808913922)                                                               | 06-2023 |
| [Towards Automated Security Analysis of Smart Contracts based on Execution Property Graph](https://arxiv.org/abs/2305.14046)         | Imperial College London, Berkeley                |                                                                                                                                         | 05-2023 |
| [DAppSCAN: Building Large-Scale Datasets for Smart Contract Weaknesses in DApp Projects](https://arxiv.org/abs/2305.08456)           | Sun Yat-sen University                           |                                                                                                                                         | 05-2023 |
|                                                                                                                                      |                                                  |                                                                                                                                         |         |
